"""This module contains functions to sweep parameter-space, creating MCNP
depletion inputs to calculate keff at EOL.
* AR
* core_z
* cool_r
* PD
* power
* enrich
"""
from pyDOE import lhs
import os
import glob
import numpy as np
import tarfile
from SALib.sample import saltelli
from SALib.analyze import sobol

from mcnp_inputs import HomogeneousInput

# set seed for reproducibility
np.random.seed(1324291)

# fixed aspect ratio
params = ('core_r', 'cool_r', 'PD', 'power', 'enrich')
ranges = {'core_r'  : (10, 50),         
          'cool_r'  : (0.5, 1),
          'PD'      : (1.1, 1.6),        
          'power'   : (80, 200),        
          'enrich'  : (0.2, 0.9)
             }


def gen_hypercube(samples, N):
    """Generate N-dimensional latin hypercube to sample dimensional reactor
    space.

    Arguments:
    ----------
        samples (int): number of test cases to try
        N (int): number of dimensions to test
    
    Returns:
    --------
        cube (ndarray): normalized, N-D latin hypercube
    """

    np.random.seed(4654562)
    hypercube = lhs(N, samples=samples)

    return hypercube

def gen_SA_inputs(N):
    """Generate inputs to perform SA.
    """

    problem = {'num_vars' : len(params),
               'names' : params,
               'bounds' : [(0,1)]*len(params)
              }

    param_space = saltelli.sample(problem, N)

    return param_space


def fill_data_array(cube):
    """Fill an ndarray with the sampling set generated by lhs.
    """
    # initialize array
    test_cases = np.zeros(len(cube), dtype={'names' : list(params),
                                            'formats' : ['f8']*6 })
    # for all samples
    for sample_idx, sample in enumerate(cube):
        # get values for every dimension
        for dim_idx, dim in enumerate(params):
            l_limit = ranges[dim][0]
            u_limit = ranges[dim][1]
            # uniform distribution
            a = u_limit - l_limit
            b = l_limit
            # save to ndarray
            test_cases[sample_idx][dim] = b + cube[sample_idx][dim_idx] * a
    
    # write the data to a csv file
    np.savetxt("data.csv", test_cases, delimiter=',',
                header=','.join(test_cases.dtype.names))
    
    return test_cases

def write_inputs(sampling_data):
    """Write MCNP depletion inputs for sampled data.
    """
    datanames = sampling_data.dtype.names
    tarputs = tarfile.open('smpl_mcnp_depl_inps.tar', 'w')
    for num, sample in enumerate(sampling_data):
        input = HomogeneousInput(sample['core_r'],
                                 sample['core_r']*1, #Length (AR=1)
                                 sample['power'])
        homog_comp = input.homog_core(sample['enrich'],
                                      sample['cool_r'],
                                      sample['PD'])
        input.write_mat_string(homog_comp)
        
        # identifying header string for post-processing
        header_str = ','.join([str(round(x, 5)) for x in sample])

        # write the input and tar it
        filename = input.write_input(num, header_str)
        tarputs.add(filename)

    # write HTC input list
    htc_inputs = open('input_files.txt', 'w')
    htc_inputs.write('\n'.join(glob.glob("*.i")))
    htc_inputs.close()
        
    tarputs.add('input_files.txt')
    tarputs.add('data.csv')
    tarputs.close()

if __name__=='__main__':
    N = len(params)
    samples = 40
#    cube = gen_hypercube(samples, N)
    sa_space = gen_SA_inputs(800)
    
    data = fill_data_array(sa_space)
    write_inputs(data)
    # cleanup
    os.system('rm *.i input_files.txt data.csv')
